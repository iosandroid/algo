{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cprintf(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        try:\n",
    "            df = df.to_frame()\n",
    "        except:\n",
    "            raise ValueError('Object cannot be coerced to df.')\n",
    "    \n",
    "    print('-'*79)\n",
    "    print('Data frame information')\n",
    "    print('-'*79)\n",
    "    print(df.tail(5))\n",
    "    print('-'*50)\n",
    "    print(df.info())\n",
    "    print('-'*79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDailyVol(close,span0=100):\n",
    "    df0 = close.index.searchsorted(close.index - pd.Timedelta(days=1))\n",
    "    df0 = df0[df0>0]\n",
    "    df0 = pd.Series(close.index[df0-1], index = close.index[close.shape[0]-df0.shape[0]:])\n",
    "\n",
    "    try:\n",
    "        df0 = close.loc[df0.index] / close.loc[df0.values].values - 1\n",
    "    except Exception as e:\n",
    "        print ('error: {e}\\n please confirm duplicate indices')\n",
    "\n",
    "    df0 = df0.ewm(span=span0).std().rename('dailyVol')\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTEvents(gRaw, h):\n",
    "    tEvents, sPos, sNeg = [], 0, 0\n",
    "    diff = np.log(gRaw).diff().dropna().abs()\n",
    "\n",
    "    for i in tqdm(diff.index[1:]):\n",
    "        try:\n",
    "            pos, neg = float(sPos + diff.loc[i]), float(sNeg + diff.loc[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(sPos + diff.loc[i], type(sPos + diff.loc[i]))\n",
    "            print(sNeg + diff.loc[i], type(sNeg + diff.loc[i]))\n",
    "            break\n",
    "        \n",
    "        sPos, sNeg = max(0.,pos), min(0.,neg)\n",
    "        if sNeg <- h:\n",
    "            sNeg = 0\n",
    "            tEvents.append(i)\n",
    "        \n",
    "        if sPos > h:\n",
    "            sPos = 0\n",
    "            tEvents.append(i)\n",
    "\n",
    "    return pd.DatetimeIndex(tEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addVerticalBarrier(tEvents, close, numDays=1):\n",
    "    t1 = close.index.searchsorted(tEvents + pd.Timedelta(days = numDays))\n",
    "    t1 = t1[t1 < close.shape[0]]\n",
    "    t1 = (pd.Series(close.index[t1], index = tEvents[:t1.shape[0]]))\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
    "    # apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
    "    events_=events.loc[molecule]\n",
    "    out=events_[['t1']].copy(deep=True)\n",
    "    \n",
    "    if ptSl[0]>0: \n",
    "        pt=ptSl[0]*events_['trgt']\n",
    "    else: \n",
    "        pt=pd.Series(index=events.index) # NaNs\n",
    "        \n",
    "    if ptSl[1]>0: \n",
    "        sl=-ptSl[1]*events_['trgt']\n",
    "    else: \n",
    "        sl=pd.Series(index=events.index) # NaNs\n",
    "        \n",
    "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0=close[loc:t1] # path prices\n",
    "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
    "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss\n",
    "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking\n",
    "    return out\n",
    "\n",
    "#def applyPtSlOnT1(close, events, ptSl, molecule):\n",
    "#    # apply stop loss / profit taking, if it takes place before t1 (end of event)\n",
    "#    events_ = events.loc[molecule]\n",
    "#    out = events_[['t1']].copy(deep=True)\n",
    "    \n",
    "#    if ptSl[0] > 0 :\n",
    "#        pt = ptSl[0] * events_['trgt']\n",
    "#    else:\n",
    "#        pt = pd.Series(index = events.index)\n",
    "    \n",
    "#    if ptSl[1] > 0:\n",
    "#        sl = -ptSl[1] * events_['trgt']\n",
    "#    else:\n",
    "#        sl = pd.Series(index = events.index)\n",
    "        \n",
    "#    for loc, t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "#        df0 = close[loc:t1]\n",
    "#        df0 = (df0 / close[loc] - 1) * events_.at[loc, 'side']\n",
    "#        out.loc[loc, 'sl'] = df0[df0 < sl[loc]].index.min()\n",
    "#        out.loc[loc, 'pt'] = df0[df0 > pt[loc]].index.min()\n",
    "        \n",
    "#    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEvents(close, tEvents, ptSl, trgt, minRet, numThreads, t1=False, side=None):\n",
    "    #1) get target\n",
    "    trgt=trgt.loc[tEvents]\n",
    "    trgt=trgt[trgt>minRet] # minRet\n",
    "    \n",
    "    #2) get t1 (max holding period)\n",
    "    if t1 is False:t1=pd.Series(pd.NaT, index=tEvents)\n",
    "        \n",
    "    #3) form events object, apply stop loss on t1\n",
    "    if side is None:\n",
    "        side_,ptSl_ = pd.Series(1.,index=trgt.index), [ptSl[0],ptSl[0]]\n",
    "    else: \n",
    "        side_, ptSl_ = side.loc[trgt.index],ptSl[:2]\n",
    "        \n",
    "    events=(pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1).dropna(subset=['trgt']))\n",
    "    \n",
    "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index),\n",
    "                    numThreads=numThreads,close=close,events=events,\n",
    "                    ptSl=ptSl_)\n",
    "    \n",
    "    events['t1']=df0.dropna(how='all').min(axis=1) # pd.min ignores nan\n",
    "    \n",
    "    if side is None:\n",
    "        events=events.drop('side',axis=1)\n",
    "        \n",
    "    return events\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import datetime as dt\n",
    "\n",
    "#________________________________\n",
    "def reportProgress(jobNum,numJobs,time0,task):\n",
    "    # Report progress as asynch jobs are completed\n",
    "    msg=[float(jobNum)/numJobs, (time.time()-time0)/60.]\n",
    "    msg.append(msg[1]*(1/msg[0]-1))\n",
    "    timeStamp=str(dt.datetime.fromtimestamp(time.time()))\n",
    "    msg=timeStamp+' '+str(round(msg[0]*100,2))+'% '+task+' done after '+ \\\n",
    "        str(round(msg[1],2))+' minutes. Remaining '+str(round(msg[2],2))+' minutes.'\n",
    "    if jobNum<numJobs:sys.stderr.write(msg+'\\r')\n",
    "    else:sys.stderr.write(msg+'\\n')\n",
    "    return\n",
    "#________________________________\n",
    "def processJobs(jobs,task=None,numThreads=24):\n",
    "    # Run in parallel.\n",
    "    # jobs must contain a 'func' callback, for expandCall\n",
    "    if task is None:task=jobs[0]['func'].__name__\n",
    "    pool=mp.Pool(processes=numThreads)\n",
    "    outputs,out,time0=pool.imap_unordered(expandCall,jobs),[],time.time()\n",
    "    # Process asyn output, report progress\n",
    "    for i,out_ in enumerate(outputs,1):\n",
    "        out.append(out_)\n",
    "        reportProgress(i,len(jobs),time0,task)\n",
    "    pool.close();pool.join() # this is needed to prevent memory leaks\n",
    "    return out\n",
    "\n",
    "def linParts(numAtoms,numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
    "    parts=np.ceil(parts).astype(int)\n",
    "    return parts\n",
    "\n",
    "def nestedParts(numAtoms,numThreads,upperTriang=False):\n",
    "    # partition of atoms with an inner loop\n",
    "    parts,numThreads_=[0],min(numThreads,numAtoms)\n",
    "    for num in range(numThreads_):\n",
    "        part=1+4*(parts[-1]**2+parts[-1]+numAtoms*(numAtoms+1.)/numThreads_)\n",
    "        part=(-1+part**.5)/2.\n",
    "        parts.append(part)\n",
    "    parts=np.round(parts).astype(int)\n",
    "    if upperTriang: # the first rows are heaviest\n",
    "        parts=np.cumsum(np.diff(parts)[::-1])\n",
    "        parts=np.append(np.array([0]),parts)\n",
    "    return parts\n",
    "\n",
    "def mpPandasObj(func, pdObj, numThreads=24, mpBatches=1, linMols=True, **kargs):\n",
    "    if linMols:\n",
    "        parts = linParts(len(pdObj[1]), numThreads * mpBatches)\n",
    "    else:\n",
    "        parts = nestedParts(len(pdObj[1]), numThreads * mpBatches)\n",
    "        \n",
    "    jobs = []\n",
    "    for i in range(1, len(parts)):\n",
    "        job = {pdObj[0] : pdObj[1][parts[i-1]:parts[i]], 'func' : func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    \n",
    "    if numThreads == 1:\n",
    "        out = processJobs_(jobs)\n",
    "    else:\n",
    "        out = processJobs(jobs, numThreads = numThreads)\n",
    "        \n",
    "    if isinstance(out[0], pd.DataFrame):\n",
    "        df0 = pd.DataFrame()\n",
    "    elif isinstance(out[0], pd.Series):\n",
    "        df0 = pd.Series()\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    for i in out:\n",
    "        df0 = df0.append(i)\n",
    "    \n",
    "    df0 = df0.sort_index()\n",
    "    return df0\n",
    "\n",
    "def processJobs_(jobs):\n",
    "    # Run jobs sequentially, for debugging\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out\n",
    "\n",
    "def expandCall(kargs):\n",
    "    # Expand the arguments of a callback function, kargs['func']\n",
    "    func=kargs['func']\n",
    "    del kargs['func']\n",
    "    out=func(**kargs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBinsOld(events,close):\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    # where out index and t1 (vertical barrier) intersect label 0\n",
    "    try:\n",
    "        locs = out.query('index in @t1').index\n",
    "        out.loc[locs, 'bin'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "def getBins(events, close):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropLabels(events, minPct=.05):\n",
    "    # apply weights, drop labels with insufficient examples\n",
    "    while True:\n",
    "        df0=events['bin'].value_counts(normalize=True)\n",
    "        if df0.min()>minPct or df0.shape[0]<3:break\n",
    "        print('dropped label: ', df0.argmin(),df0.min())\n",
    "        events=events[events['bin']!=df0.argmin()]\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                        amount        price  dollar_volume     volume\n",
      "dates                                                                \n",
      "2018-07-23 15:25:31 -40.000000  7700.000000 -308000.000000 -40.000000\n",
      "2018-07-23 15:29:11  31.444802  7700.000000  242124.976632  31.444802\n",
      "2018-07-23 15:32:09   8.000000  7719.000000   61752.000000   8.000000\n",
      "2018-07-23 15:36:58   0.200000  7733.000000    1546.600000   0.200000\n",
      "2018-07-23 15:40:01   0.996000  7731.245984    7700.321000   0.996000\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4943 entries, 2018-07-08 19:41:28 to 2018-07-23 15:40:01\n",
      "Data columns (total 4 columns):\n",
      "amount           4943 non-null float64\n",
      "price            4943 non-null float64\n",
      "dollar_volume    4943 non-null float64\n",
      "volume           4943 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 193.1 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/dollar_bars.csv', index_col='dates').drop_duplicates()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "cprintf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     dailyVol\n",
      "dates                        \n",
      "2018-07-23 15:25:31  0.004040\n",
      "2018-07-23 15:29:11  0.004130\n",
      "2018-07-23 15:32:09  0.004008\n",
      "2018-07-23 15:36:58  0.003973\n",
      "2018-07-23 15:40:01  0.003834\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4485 entries, 2018-07-09 19:58:11 to 2018-07-23 15:40:01\n",
      "Data columns (total 1 columns):\n",
      "dailyVol    4484 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 70.1 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "close = df.price.copy()\n",
    "close = close[~close.index.duplicated(keep='first')]\n",
    "\n",
    "dailyVol = getDailyVol(close, 24)\n",
    "cprintf(dailyVol.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ffb8a2fff90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f,ax = plt.subplots()\n",
    "dailyVol.plot(ax=ax)\n",
    "ax.axhline(dailyVol.mean(), ls='--', color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4665/4665 [00:00<00:00, 14256.72it/s] | 1302/4665 [00:00<00:00, 13014.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-07-08 21:50:16', '2018-07-08 23:04:36',\n",
       "               '2018-07-08 23:07:47', '2018-07-08 23:08:30',\n",
       "               '2018-07-08 23:43:27', '2018-07-09 00:11:32',\n",
       "               '2018-07-09 00:42:10', '2018-07-09 01:14:56',\n",
       "               '2018-07-09 03:35:13', '2018-07-09 06:12:35',\n",
       "               ...\n",
       "               '2018-07-23 11:16:28', '2018-07-23 11:40:02',\n",
       "               '2018-07-23 11:52:34', '2018-07-23 12:07:18',\n",
       "               '2018-07-23 12:49:57', '2018-07-23 13:18:08',\n",
       "               '2018-07-23 13:59:23', '2018-07-23 14:38:40',\n",
       "               '2018-07-23 15:08:55', '2018-07-23 15:36:58'],\n",
       "              dtype='datetime64[ns]', length=944, freq=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tEvents = getTEvents(close, h = dailyVol.mean())\n",
    "tEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-07-08 21:50:16', '2018-07-08 23:04:36',\n",
       "               '2018-07-08 23:07:47', '2018-07-08 23:08:30',\n",
       "               '2018-07-08 23:43:27', '2018-07-09 00:11:32',\n",
       "               '2018-07-09 00:42:10', '2018-07-09 01:14:56',\n",
       "               '2018-07-09 03:35:13', '2018-07-09 06:12:35',\n",
       "               ...\n",
       "               '2018-07-22 11:52:04', '2018-07-22 13:22:50',\n",
       "               '2018-07-22 13:54:52', '2018-07-22 14:23:26',\n",
       "               '2018-07-22 14:43:24', '2018-07-22 14:48:15',\n",
       "               '2018-07-22 15:02:15', '2018-07-22 15:18:49',\n",
       "               '2018-07-22 15:25:56', '2018-07-22 15:34:06'],\n",
       "              dtype='datetime64[ns]', length=841, freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = addVerticalBarrier(tEvents, close)\n",
    "t1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  app.launch_new_instance()\n",
      "2018-08-25 05:45:13.881899 66.67% applyPtSlOnT1 done after 0.0 minutes. Remaining 0.0 minutes.2018-08-25 05:45:13.882002 100.0% applyPtSlOnT1 done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "ptSl = [1,1]\n",
    "target = dailyVol\n",
    "minRet = 0.01\n",
    "cpus = cpu_count() - 1\n",
    "\n",
    "events = getEvents(close, tEvents, ptSl, target, minRet, cpus, t1=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                                     t1      trgt\n",
      "2018-07-20 16:40:28 2018-07-20 16:43:09  0.012766\n",
      "2018-07-20 16:41:19 2018-07-20 16:58:36  0.011954\n",
      "2018-07-20 17:03:43 2018-07-20 18:01:39  0.010749\n",
      "2018-07-20 17:03:48 2018-07-20 18:01:39  0.011086\n",
      "2018-07-20 17:04:32 2018-07-20 17:54:30  0.010653\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 41 entries, 2018-07-11 11:44:37 to 2018-07-20 17:04:32\n",
      "Data columns (total 2 columns):\n",
      "t1      41 non-null datetime64[ns]\n",
      "trgt    41 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 984.0 bytes\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cprintf(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    19\n",
       "-1.0    16\n",
       " 0.0     6\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = getBinsOld(events, close)\n",
    "labels.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    19\n",
       "-1.0    16\n",
       " 0.0     6\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_labels = dropLabels(labels)\n",
    "clean_labels.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffb85705590>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "l0 = labels[labels['bin'] > 0]\n",
    "l1 = labels[labels['bin'] < 0]\n",
    "\n",
    "c0 = close.loc[l0.index]\n",
    "c1 = close.loc[l1.index]\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "close.plot(ax=ax)\n",
    "c0.plot(ax=ax, ls = '', marker = '^', markersize = 7, color = 'g')\n",
    "c1.plot(ax=ax, ls = '', marker = 'v', markersize = 7, color = 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                           price         fast         slow\n",
      "dates                                                     \n",
      "2018-07-23 15:25:31  7706.600000  7703.899255  7704.372340\n",
      "2018-07-23 15:29:11  7700.000000  7702.924441  7703.825798\n",
      "2018-07-23 15:32:09  7719.000000  7706.943331  7705.722573\n",
      "2018-07-23 15:36:58  7733.000000  7713.457498  7709.132251\n",
      "2018-07-23 15:40:01  7731.245984  7717.904620  7711.896468\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4667 entries, 2018-07-08 19:41:28 to 2018-07-23 15:40:01\n",
      "Data columns (total 3 columns):\n",
      "price    4667 non-null float64\n",
      "fast     4667 non-null float64\n",
      "slow     4667 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 145.8 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fast_window = 3\n",
    "slow_window = 7\n",
    "\n",
    "close_df = (pd.DataFrame().assign(price=close).assign(fast=close.ewm(fast_window).mean()).assign(slow=close.ewm(slow_window).mean()))\n",
    "cprintf(close_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffb76385c90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_up_cross(df):\n",
    "    crit1 = df.fast.shift(1) < df.slow.shift(1)\n",
    "    crit2 = df.fast > df.slow\n",
    "    return df.fast[(crit1) & (crit2)]\n",
    "\n",
    "def get_down_cross(df):\n",
    "    crit1 = df.fast.shift(1) > df.slow.shift(1)\n",
    "    crit2 = df.fast < df.slow\n",
    "    return df.fast[(crit1) & (crit2)]\n",
    "\n",
    "up = get_up_cross(close_df)\n",
    "down = get_down_cross(close_df)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11,8))\n",
    "\n",
    "close_df.plot(ax=ax, alpha=.5)\n",
    "up.plot(ax=ax, ls = '', marker='^', markersize=7, alpha=.75, label='upcross', color='g')\n",
    "down.plot(ax=ax, ls = '', marker='v', markersize=7, alpha=.75, label='downcross', color='r')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     0\n",
      "dates                 \n",
      "2018-07-23 12:01:20  1\n",
      "2018-07-23 12:22:04 -1\n",
      "2018-07-23 12:49:57  1\n",
      "2018-07-23 14:38:40 -1\n",
      "2018-07-23 15:32:09  1\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 285 entries, 2018-07-08 20:36:54 to 2018-07-23 15:32:09\n",
      "Data columns (total 1 columns):\n",
      "0    285 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 4.5 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "side_up = pd.Series(1, index=up.index)\n",
    "side_down = pd.Series(-1, index=down.index)\n",
    "side = pd.concat([side_up, side_down]).sort_index()\n",
    "cprintf(side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:13: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "2018-08-25 05:45:32.376507 66.67% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes..2018-08-25 05:45:32.408000 100.0% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1.0    40\n",
       "-1.0    33\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minRet = .000001\n",
    "ptsl=[1,2]\n",
    "ma_events = getEvents(close, tEvents, ptsl, target, minRet, cpus, t1=t1, side=side)\n",
    "ma_events.side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          ret  bin  side\n",
      "2018-07-23 06:45:11  0.002901  1.0     1\n",
      "2018-07-23 07:06:05 -0.008918  0.0    -1\n",
      "2018-07-23 07:16:46  0.003747  1.0     1\n",
      "2018-07-23 12:49:57  0.002389  1.0     1\n",
      "2018-07-23 14:38:40 -0.004481  0.0    -1\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 73 entries, 2018-07-09 21:28:34 to 2018-07-23 14:38:40\n",
      "Data columns (total 3 columns):\n",
      "ret     73 non-null float64\n",
      "bin     73 non-null float64\n",
      "side    73 non-null int64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.3 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ma_side = ma_events.dropna().side\n",
    "ma_bins = getBins(ma_events,close).dropna()\n",
    "\n",
    "Xx = pd.merge_asof(ma_bins, side.to_frame().rename(columns={0: 'side'}), left_index=True, right_index=True, direction='forward')\n",
    "cprintf(Xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffb762e9790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "l0 = Xx[Xx['side'] > 0]\n",
    "l1 = Xx[Xx['side'] < 0]\n",
    "\n",
    "c0 = close.loc[l0.index]\n",
    "c1 = close.loc[l1.index]\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "close.plot(ax=ax)\n",
    "c0.plot(ax=ax, ls = '', marker = '^', markersize = 7, color = 'g')\n",
    "c1.plot(ax=ax, ls = '', marker = 'v', markersize = 7, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=777,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 777\n",
    "\n",
    "X = ma_side.values.reshape(-1,1)\n",
    "y = ma_bins.bin.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "n_estimator = 100\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=n_estimator, criterion='entropy', random_state=RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.59      0.62      0.61        16\n",
      "        1.0       0.70      0.67      0.68        21\n",
      "\n",
      "avg / total       0.65      0.65      0.65        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict_proba(X_test)[:,1]\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbands(price, window=None, width=None, numsd=None):\n",
    "    \"\"\" returns average, upper band, and lower band\"\"\"\n",
    "    ave = price.rolling(window).mean()\n",
    "    sd = price.rolling(window).std(ddof=0)\n",
    "    if width:\n",
    "        upband = ave * (1+width)\n",
    "        dnband = ave * (1-width)\n",
    "        return price, np.round(ave,3), np.round(upband,3), np.round(dnband,3)        \n",
    "    if numsd:\n",
    "        upband = ave + (sd*numsd)\n",
    "        dnband = ave - (sd*numsd)        \n",
    "        return price, np.round(ave,3), np.round(upband,3), np.round(dnband,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                           price       ave     upper     lower\n",
      "dates                                                         \n",
      "2018-07-23 15:25:31  7706.600000  7693.472  7712.102  7674.842\n",
      "2018-07-23 15:29:11  7700.000000  7693.970  7712.434  7675.506\n",
      "2018-07-23 15:32:09  7719.000000  7694.952  7713.416  7676.489\n",
      "2018-07-23 15:36:58  7733.000000  7696.432  7714.920  7677.944\n",
      "2018-07-23 15:40:01  7731.245984  7697.819  7716.266  7679.372\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4618 entries, 2018-07-09 04:58:17 to 2018-07-23 15:40:01\n",
      "Data columns (total 4 columns):\n",
      "price    4618 non-null float64\n",
      "ave      4618 non-null float64\n",
      "upper    4618 non-null float64\n",
      "lower    4618 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 180.4 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "window=50\n",
    "bb_df = pd.DataFrame()\n",
    "bb_df['price'],bb_df['ave'],bb_df['upper'],bb_df['lower']=bbands(close, window=window, numsd=1)\n",
    "bb_df.dropna(inplace=True)\n",
    "cprintf(bb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffb71cbae50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f,ax=plt.subplots(figsize=(11,8))\n",
    "bb_df.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffb71825f50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_up_cross(df, col):\n",
    "    # col is price column\n",
    "    crit1 = df[col].shift(1) < df.upper.shift(1)  \n",
    "    crit2 = df[col] > df.upper\n",
    "    return df[col][(crit1) & (crit2)]\n",
    "\n",
    "def get_down_cross(df, col):\n",
    "    # col is price column    \n",
    "    crit1 = df[col].shift(1) > df.lower.shift(1) \n",
    "    crit2 = df[col] < df.lower\n",
    "    return df[col][(crit1) & (crit2)]\n",
    "\n",
    "bb_down = get_down_cross(bb_df, 'price')\n",
    "bb_up = get_up_cross(bb_df, 'price') \n",
    "\n",
    "f, ax = plt.subplots(figsize=(11,8))\n",
    "\n",
    "bb_df.plot(ax=ax, alpha=.5)\n",
    "bb_up.plot(ax=ax, ls='', marker='^', markersize=7, alpha=0.75, label='upcross', color='g')\n",
    "bb_down.plot(ax=ax, ls='', marker='v', markersize=7,alpha=0.75, label='downcross', color='r')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     0\n",
      "dates                 \n",
      "2018-07-23 11:37:10  1\n",
      "2018-07-23 12:18:28  1\n",
      "2018-07-23 12:31:42  1\n",
      "2018-07-23 12:53:28 -1\n",
      "2018-07-23 15:32:09 -1\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 356 entries, 2018-07-09 07:29:13 to 2018-07-23 15:32:09\n",
      "Data columns (total 1 columns):\n",
      "0    356 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 5.6 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:13: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     side  t1      trgt\n",
      "2018-07-23 13:18:08   NaN NaT  0.002966\n",
      "2018-07-23 13:59:23   NaN NaT  0.002460\n",
      "2018-07-23 14:38:40   NaN NaT  0.002215\n",
      "2018-07-23 15:08:55   NaN NaT  0.003308\n",
      "2018-07-23 15:36:58   NaN NaT  0.003973\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 914 entries, 2018-07-09 21:28:34 to 2018-07-23 15:36:58\n",
      "Data columns (total 3 columns):\n",
      "side    115 non-null float64\n",
      "t1      819 non-null datetime64[ns]\n",
      "trgt    914 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 28.6 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     side\n",
      "2018-07-22 21:20:18   1.0\n",
      "2018-07-22 22:49:24  -1.0\n",
      "2018-07-23 04:30:35  -1.0\n",
      "2018-07-23 06:48:50  -1.0\n",
      "2018-07-23 08:05:22   1.0\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 109 entries, 2018-07-09 23:15:16 to 2018-07-23 08:05:22\n",
      "Data columns (total 1 columns):\n",
      "side    109 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.7 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-25 07:37:18.088954 33.33% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.02 minutes.\r",
      "2018-08-25 07:37:18.093438 66.67% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes.\r",
      "2018-08-25 07:37:18.100752 100.0% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "bb_side_up = pd.Series(-1, index=bb_up.index) # sell on up cross for mean reversion\n",
    "bb_side_down = pd.Series(1, index=bb_down.index) # buy on down cross for mean reversion\n",
    "bb_side_raw = pd.concat([bb_side_up,bb_side_down]).sort_index()\n",
    "cprintf(bb_side_raw)\n",
    "\n",
    "minRet = .001 \n",
    "ptsl=[0,2]\n",
    "bb_events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1,side=bb_side_raw)\n",
    "cprintf(bb_events)\n",
    "\n",
    "bb_side = bb_events.dropna().side\n",
    "cprintf(bb_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    56\n",
       " 1.0    53\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          ret  bin\n",
      "2018-07-22 21:20:18 -0.008944  0.0\n",
      "2018-07-22 22:49:24 -0.007765  0.0\n",
      "2018-07-23 04:30:35 -0.008096  0.0\n",
      "2018-07-23 06:48:50 -0.010121  0.0\n",
      "2018-07-23 08:05:22 -0.004784  0.0\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 109 entries, 2018-07-09 23:15:16 to 2018-07-23 08:05:22\n",
      "Data columns (total 2 columns):\n",
      "ret    109 non-null float64\n",
      "bin    109 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 2.6 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bb_bins = getBins(bb_events,close).dropna()\n",
    "cprintf(bb_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    93\n",
       "1.0    16\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_bins.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returns(s):\n",
    "    arr = np.diff(np.log(s))\n",
    "    return (pd.Series(arr, index=s.index[1:]))\n",
    "\n",
    "def df_rolling_autocorr(df, window, lag=1):\n",
    "    \"\"\"Compute rolling column-wise autocorrelation for a DataFrame.\"\"\"\n",
    "\n",
    "    return (df.rolling(window=window)\n",
    "            .corr(df.shift(lag))) # could .dropna() here\n",
    "\n",
    "#df_rolling_autocorr(d1, window=21).dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     srl_corr\n",
      "dates                        \n",
      "2018-07-23 15:25:31 -0.009523\n",
      "2018-07-23 15:29:11 -0.019654\n",
      "2018-07-23 15:32:09 -0.073255\n",
      "2018-07-23 15:36:58 -0.017369\n",
      "2018-07-23 15:40:01 -0.024611\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4666 entries, 2018-07-08 20:16:45 to 2018-07-23 15:40:01\n",
      "Data columns (total 1 columns):\n",
      "srl_corr    4616 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 72.9 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "srl_corr = df_rolling_autocorr(returns(close), window=window).rename('srl_corr')\n",
    "cprintf(srl_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          vol  ma_side  srl_corr\n",
      "2018-07-23 06:45:11  0.002585      1.0 -0.016879\n",
      "2018-07-23 07:06:05  0.004033     -1.0 -0.151176\n",
      "2018-07-23 07:16:46  0.002935      1.0 -0.333736\n",
      "2018-07-23 12:49:57  0.001945      1.0 -0.093937\n",
      "2018-07-23 14:38:40  0.002215     -1.0  0.112511\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 73 entries, 2018-07-09 21:28:34 to 2018-07-23 14:38:40\n",
      "Data columns (total 3 columns):\n",
      "vol         73 non-null float64\n",
      "ma_side     73 non-null float64\n",
      "srl_corr    73 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.3 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "features = (pd.DataFrame()\n",
    "            .assign(vol=bb_events.trgt)\n",
    "            .assign(ma_side=ma_side)\n",
    "            .assign(srl_corr=srl_corr)\n",
    "            .drop_duplicates()\n",
    "            .dropna())\n",
    "cprintf(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          vol  ma_side  srl_corr  bin\n",
      "2018-07-23 03:37:33  0.002462     -1.0 -0.065742  0.0\n",
      "2018-07-23 04:30:35  0.003797      1.0 -0.071414  0.0\n",
      "2018-07-23 06:45:11  0.002585      1.0 -0.016879  0.0\n",
      "2018-07-23 07:06:05  0.004033     -1.0 -0.151176  0.0\n",
      "2018-07-23 07:16:46  0.002935      1.0 -0.333736  0.0\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 71 entries, 2018-07-09 21:28:34 to 2018-07-23 07:16:46\n",
      "Data columns (total 4 columns):\n",
      "vol         71 non-null float64\n",
      "ma_side     71 non-null float64\n",
      "srl_corr    71 non-null float64\n",
      "bin         71 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 2.8 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Xy = (pd.merge_asof(features, bb_bins[['bin']], \n",
    "                    left_index=True, right_index=True, \n",
    "                    direction='forward').dropna())\n",
    "cprintf(Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    60\n",
       "1.0    11\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   no_trade       0.50      0.18      0.27        11\n",
      "      trade       0.67      0.90      0.77        20\n",
      "\n",
      "avg / total       0.61      0.65      0.59        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = Xy.drop('bin',axis=1).values\n",
    "y = Xy['bin'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "n_estimator = 1000\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred, target_names=['no_trade','trade']))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  app.launch_new_instance()\n",
      "2018-08-26 01:13:08.503063 66.67% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes..2018-08-26 01:13:08.522102 100.0% applyPtSlOnT1 done after 0.01 minutes. Remaining 0.0 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                     t1      trgt\n",
      "2018-07-23 13:18:08 NaT  0.002966\n",
      "2018-07-23 13:59:23 NaT  0.002460\n",
      "2018-07-23 14:38:40 NaT  0.002215\n",
      "2018-07-23 15:08:55 NaT  0.003308\n",
      "2018-07-23 15:36:58 NaT  0.003973\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 914 entries, 2018-07-09 21:28:34 to 2018-07-23 15:36:58\n",
      "Data columns (total 2 columns):\n",
      "t1      811 non-null datetime64[ns]\n",
      "trgt    914 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 21.4 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          ret  bin\n",
      "2018-07-22 14:48:15  0.029504  1.0\n",
      "2018-07-22 15:02:15  0.028251  1.0\n",
      "2018-07-22 15:18:49  0.023453  1.0\n",
      "2018-07-22 15:25:56  0.022576  1.0\n",
      "2018-07-22 15:34:06  0.026005  1.0\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 811 entries, 2018-07-09 21:28:34 to 2018-07-22 15:34:06\n",
      "Data columns (total 2 columns):\n",
      "ret    811 non-null float64\n",
      "bin    811 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 19.0 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          vol  ma_side  srl_corr\n",
      "2018-07-23 06:45:11  0.002585      1.0 -0.016879\n",
      "2018-07-23 07:06:05  0.004033     -1.0 -0.151176\n",
      "2018-07-23 07:16:46  0.002935      1.0 -0.333736\n",
      "2018-07-23 12:49:57  0.001945      1.0 -0.093937\n",
      "2018-07-23 14:38:40  0.002215     -1.0  0.112511\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 73 entries, 2018-07-09 21:28:34 to 2018-07-23 14:38:40\n",
      "Data columns (total 3 columns):\n",
      "vol         73 non-null float64\n",
      "ma_side     73 non-null float64\n",
      "srl_corr    73 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.3 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Data frame information\n",
      "-------------------------------------------------------------------------------\n",
      "                          vol  ma_side  srl_corr  bin\n",
      "2018-07-21 01:43:14  0.003794      1.0 -0.181317  1.0\n",
      "2018-07-21 08:50:15  0.006273     -1.0 -0.172600  1.0\n",
      "2018-07-21 11:54:01  0.005106      1.0  0.018342  1.0\n",
      "2018-07-21 12:26:18  0.004919      1.0 -0.044443  1.0\n",
      "2018-07-22 08:10:19  0.005279      1.0 -0.163193  1.0\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 61 entries, 2018-07-09 21:28:34 to 2018-07-22 08:10:19\n",
      "Data columns (total 4 columns):\n",
      "vol         61 non-null float64\n",
      "ma_side     61 non-null float64\n",
      "srl_corr    61 non-null float64\n",
      "bin         61 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 2.4 KB\n",
      "None\n",
      "-------------------------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.50      0.10      0.17        10\n",
      "        1.0       0.69      0.95      0.80        21\n",
      "\n",
      "avg / total       0.63      0.68      0.60        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minRet = .001 \n",
    "ptsl=[0,2]\n",
    "bb_events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1)\n",
    "cprintf(bb_events)\n",
    "\n",
    "bb_bins = getBins(bb_events,close).dropna()\n",
    "cprintf(bb_bins)\n",
    "\n",
    "features = (pd.DataFrame()\n",
    "            .assign(vol=bb_events.trgt)\n",
    "            .assign(ma_side=ma_side)\n",
    "            .assign(srl_corr=srl_corr)\n",
    "            .drop_duplicates()\n",
    "            .dropna())\n",
    "cprintf(features)\n",
    "\n",
    "Xy = (pd.merge_asof(features, bb_bins[['bin']], \n",
    "                    left_index=True, right_index=True, \n",
    "                    direction='forward').dropna())\n",
    "cprintf(Xy)\n",
    "\n",
    "### run model ###\n",
    "X = Xy.drop('bin',axis=1).values\n",
    "y = Xy['bin'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "n_estimator = 100\n",
    "rf = RandomForestClassifier(max_depth=4, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
