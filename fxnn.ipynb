{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('EURUSD1.csv', names=['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "train = np.array(df.Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcReturns(data):\n",
    "    R = []    \n",
    "    for i in range(len(data)-1):\n",
    "        v = math.log(math.fabs(data[i+1]/data[i]))\n",
    "        R.append(v)\n",
    "        \n",
    "    return R\n",
    "\n",
    "def ZigZag(data, minsize):\n",
    "    \n",
    "    N = 0\n",
    "    Z = {'zigzag': [], 'time': [], 'label' : []}\n",
    "    \n",
    "    T = N\n",
    "    \n",
    "    Count = 0;\n",
    "    \n",
    "    Max  = data[0]\n",
    "    Min  = data[0]\n",
    "    \n",
    "    Flag = False\n",
    "    \n",
    "    PriceLow = 0\n",
    "    PriceHigh = 0    \n",
    "        \n",
    "    while N < len(data):\n",
    "        \n",
    "        PriceLow = data[N]\n",
    "        PriceHigh = data[N]        \n",
    "        \n",
    "        if Flag:\n",
    "            \n",
    "            if PriceHigh > Max:\n",
    "                \n",
    "                T = N\n",
    "                Max = PriceHigh                \n",
    "                \n",
    "            elif (Max - PriceLow >= minsize):\n",
    "                \n",
    "                Z['time'].append(T)\n",
    "                Z['label'].append(-1)\n",
    "                Z['zigzag'].append(Max)\n",
    "                \n",
    "                Flag = False\n",
    "                Count = Count + 1                                \n",
    "                \n",
    "                T = N\n",
    "                Min = PriceLow                \n",
    "                \n",
    "        else:\n",
    "               \n",
    "            if PriceLow < Min:\n",
    "                \n",
    "                T = N\n",
    "                Min = PriceLow                \n",
    "                    \n",
    "            elif (PriceHigh - Min >= minsize):\n",
    "                    \n",
    "                Z['time'].append(T)\n",
    "                Z['label'].append(1)\n",
    "                Z['zigzag'].append(Min)\n",
    "                \n",
    "                Flag = True\n",
    "                Count = Count + 1                \n",
    "                \n",
    "                T = N\n",
    "                Max = PriceHigh                 \n",
    "    \n",
    "        N = N + 1    \n",
    "\n",
    "    return Z\n",
    "\n",
    "def BuildData3(zigzag, returns, lag):\n",
    "    \n",
    "    D = []\n",
    "    L = []\n",
    "    \n",
    "    D0 = []\n",
    "    D1 = []\n",
    "    \n",
    "    L0 = []\n",
    "    L1 = []\n",
    "    \n",
    "    N = len(returns) + 1\n",
    "    Count = len(Z['time'])\n",
    "\n",
    "    for i in range(0,N-lag):        \n",
    "        try:\n",
    "            index = zigzag[\"time\"].index(i+lag-1)\n",
    "            \n",
    "            D0.append(returns[i:i+lag-1])\n",
    "            \n",
    "            if zigzag[\"label\"][index] == 1:                \n",
    "                L0.append([0, 0, 1])\n",
    "            else:\n",
    "                L0.append([1, 0, 0])\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            D1.append(returns[i:i+lag-1])\n",
    "            L1.append([0, 1, 0])\n",
    "\n",
    "    Count0 = len(D0)\n",
    "    Count1 = len(D1)\n",
    "    \n",
    "    #print(Count0, Count1)\n",
    "    \n",
    "    N = Count0 / 2\n",
    "    if Count1 > N:        \n",
    "        D1 = np.random.permutation(D1)\n",
    "        \n",
    "        D = D1[:N]\n",
    "        L = L1[:N]\n",
    "        \n",
    "    else:        \n",
    "        D = D1\n",
    "        L = L1\n",
    "    \n",
    "    D_temp = np.concatenate((D, D0), axis=0)\n",
    "    L_temp = np.concatenate((L, L0), axis=0)\n",
    "    \n",
    "    I = range(len(D_temp))\n",
    "    I = np.random.permutation(I)\n",
    "    \n",
    "    D = []\n",
    "    L = []\n",
    "    \n",
    "    for i in I:\n",
    "        D.append(D_temp[i])\n",
    "        L.append(L_temp[i])\n",
    "    \n",
    "    D = np.array(D)\n",
    "    L = np.array(L)   \n",
    "    \n",
    "    D = preprocessing.scale(D)\n",
    "    \n",
    "    return D, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7609, 60)\n"
     ]
    }
   ],
   "source": [
    "Z = ZigZag(train, 0.0004)\n",
    "returns = CalcReturns(train)\n",
    "\n",
    "D, L = BuildData3(Z, returns, 61)\n",
    "t_count = 1024\n",
    "\n",
    "dims = D.shape[1]\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neural_network_model(x):\n",
    "\n",
    "    hl1 = {'w' : tf.Variable(tf.random_normal([dims, n_nodes_hl1])),\n",
    "           'b' : tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hl2 = {'w' : tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "           'b' : tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hl3 = {'w' : tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "           'b' : tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    \n",
    "    hl4 = {'w' : tf.Variable(tf.random_normal([n_nodes_hl3, n_nodes_hl4])),\n",
    "           'b' : tf.Variable(tf.random_normal([n_nodes_hl4]))}\n",
    "\n",
    "    out = {'w' : tf.Variable(tf.random_normal([n_nodes_hl4, n_classes])),\n",
    "           'b' : tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    l1 = tf.matmul(x, hl1['w']) + hl1['b']\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.matmul(l1, hl2['w']) + hl2['b']\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.matmul(l2, hl3['w']) + hl3['b']\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    l4 = tf.matmul(l3, hl4['w']) + hl4['b']\n",
    "    l4 = tf.tanh(l4)\n",
    "\n",
    "    y = tf.matmul(l1, out['w']) + out['b']\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "def train_neural_network(x,y):\n",
    "    nn = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = nn, labels = y))\n",
    "    optimizer = tf.train.AdamOptimizer(0.6).minimize(cost)   \n",
    "    \n",
    "    correct = tf.equal(tf.argmax(nn,1), tf.argmax(y_train, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(int((len(D) - t_count)/batch_size)):\n",
    "                \n",
    "                epoch_x = D[i*batch_size : (i+1)*batch_size]\n",
    "                epoch_y = L[i*batch_size : (i+1)*batch_size]\n",
    "                \n",
    "                _, c = session.run([optimizer, cost], feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "                \n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch', epoch, 'completed out of', hm_epochs, 'loss', epoch_loss)\n",
    "                saver.save(session, 'data/fxnn.ckpt')\n",
    "\n",
    "        print('Last epoch loss: ', epoch_loss)\n",
    "        return nn, correct, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_neural_network(x_test, y_test, nn, correct, accuracy):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as session:\n",
    "        saver.restore(session, 'data/fxnn.ckpt')\n",
    "        r = tf.cast(correct, 'float').eval({x_train:x_test, y_train:y_test})\n",
    "        \n",
    "        test_buy  = 0.0\n",
    "        test_sell = 0.0\n",
    "        test_hold = 0.0\n",
    "\n",
    "        correct_buy  = 0.0\n",
    "        correct_sell = 0.0\n",
    "        correct_hold = 0.0\n",
    "\n",
    "        incorrect_buy  = 0.0\n",
    "        incorrect_sell = 0.0\n",
    "        incorrect_hold = 0.0\n",
    "        \n",
    "        for i in range(len(r)):\n",
    "            if L[i][2] == 1:\n",
    "                test_buy += 1.0;\n",
    "            elif L[i][1] == 1:\n",
    "                test_hold += 1.0;\n",
    "            elif L[i][0] == 1:\n",
    "                test_sell += 1.0;\n",
    "                \n",
    "            if r[i] == 1:\n",
    "                if L[i][2] == 1:\n",
    "                    correct_buy += 1.0;\n",
    "                elif L[i][1] == 1:\n",
    "                    correct_hold += 1.0;\n",
    "                elif L[i][0] == 1:\n",
    "                    correct_sell += 1.0;\n",
    "            else:\n",
    "                if L[i][2] == 1:\n",
    "                    incorrect_buy += 1.0;\n",
    "                elif L[i][1] == 1:\n",
    "                    incorrect_hold += 1.0;\n",
    "                elif L[i][0] == 1:\n",
    "                    incorrect_sell += 1.0;\n",
    "        \n",
    "        print('Accuracy:',accuracy.eval({x_train:x_test, y_train:y_test}))\n",
    "        \n",
    "        print( \"Test buy:  \", test_buy  )\n",
    "        print( \"Test sell: \", test_sell )\n",
    "        print( \"Test hold: \", test_hold )\n",
    "\n",
    "        print( \"Correct buy:  \", correct_buy,  \"Incorrect buy:  \", incorrect_buy,  \"Accuracy: \", (correct_buy/test_buy)*100 )\n",
    "        print( \"Correct sell: \", correct_sell, \"Incorrect sell: \", incorrect_sell, \"Accuracy: \", (correct_sell/test_sell)*100 )\n",
    "        print( \"Correct hold: \", correct_hold, \"Incorrect hold: \", incorrect_hold, \"Accuracy: \", (correct_hold/test_hold)*100 )\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-a964ca1bdb93>:15: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Epoch', 0, 'completed out of', 1000, 'loss', 32264.30387878418)\n",
      "('Epoch', 100, 'completed out of', 1000, 'loss', 256.00764094293118)\n",
      "('Epoch', 200, 'completed out of', 1000, 'loss', 182.26772302761674)\n",
      "('Epoch', 300, 'completed out of', 1000, 'loss', 230.61531361669768)\n",
      "('Epoch', 400, 'completed out of', 1000, 'loss', 8858.4657707214355)\n",
      "('Epoch', 500, 'completed out of', 1000, 'loss', 378.63081178069115)\n",
      "('Epoch', 600, 'completed out of', 1000, 'loss', 134.10962216556072)\n",
      "('Epoch', 700, 'completed out of', 1000, 'loss', 11864.234266143292)\n",
      "('Epoch', 800, 'completed out of', 1000, 'loss', 16304.535191189498)\n",
      "('Epoch', 900, 'completed out of', 1000, 'loss', 119.80659198644571)\n",
      "('Last epoch loss: ', 2865.2229010617011)\n"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 1000\n",
    "n_nodes_hl2 = 1000\n",
    "n_nodes_hl3 = 1000\n",
    "n_nodes_hl4 = 1000\n",
    "\n",
    "n_classes = 3\n",
    "hm_epochs = 1000\n",
    "\n",
    "x_train = tf.placeholder('float', [None, 60])\n",
    "y_train = tf.placeholder('float')\n",
    "\n",
    "nn, correct, accuracy = train_neural_network(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.66503906)\n",
      "('Test buy:  ', 330.0)\n",
      "('Test sell: ', 341.0)\n",
      "('Test hold: ', 353.0)\n",
      "('Correct buy:  ', 232.0, 'Incorrect buy:  ', 98.0, 'Accuracy: ', 70.3030303030303)\n",
      "('Correct sell: ', 228.0, 'Incorrect sell: ', 113.0, 'Accuracy: ', 66.86217008797654)\n",
      "('Correct hold: ', 221.0, 'Incorrect hold: ', 132.0, 'Accuracy: ', 62.606232294617556)\n"
     ]
    }
   ],
   "source": [
    "x_test = D[len(D)-t_count:]\n",
    "y_test = L[len(L)-t_count:]\n",
    "\n",
    "test_neural_network(x_test, y_test, nn, correct, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "LOG_DIR = 'data/logs'\n",
    "metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "data = tf.Variable(D, name='fxnn')\n",
    "\n",
    "with open(metadata_path, 'w') as metadata_file:\n",
    "    for label in L:\n",
    "        if label[0] == 1:\n",
    "            metadata_file.write('-1\\n')\n",
    "        elif label[1] == 1:\n",
    "            metadata_file.write('0\\n')\n",
    "        elif label[2] == 1:\n",
    "            metadata_file.write('1\\n')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([data])\n",
    "\n",
    "    sess.run(data.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'fxnn.ckpt'))\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    \n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = data.name\n",
    "    \n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = 'logs/metadata.tsv'\n",
    "    \n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
